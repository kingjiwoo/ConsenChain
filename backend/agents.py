# backend/agents.py

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import openai
from langchain.schema import HumanMessage, SystemMessage
from langchain.agents import OpenAIFunctionsAgent
from langchain.prompts import MessagesPlaceholder
from knowledge import KnowledgeBase
from llm import LLMSingleton
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).resolve().parent
parent_dir = current_dir.parent
sys.path.append(str(parent_dir))

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ê²½ë¡œ ì„¤ì •
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise Exception("Please set your OPENAI_API_KEY in the .env file.")

# LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm = ChatOpenAI(
    model_name="gpt-4o-mini", 
    temperature=0.7,
    openai_api_key=OPENAI_API_KEY
)


@dataclass
class AgentProfile:
    concept: Dict[str, str]  # ì§ì—…, ì„±ê²©, ê²¬í•´, ì´í•´ê´€ê³„, ëª©ì 
    name: str = None
    knowledge_base: KnowledgeBase = None
    goals: List[str] = None
    shared_knowledge: List[str] = None  # ê³µí†µ ì§€ì‹
    personality: Dict[str, Any] = None  # ì„±ê²© íŠ¹ì„±
    negotiation_style: Dict[str, Any] = None  # í˜‘ìƒ ìŠ¤íƒ€ì¼
    consensus_preferences: Dict[str, Any] = None  # í•©ì˜ ì„ í˜¸ë„
    language_style: Dict[str, str] = None  # ì–¸ì–´ ìŠ¤íƒ€ì¼

    def __post_init__(self):
        self.name = self.name or "unnamed_agent"
        self.knowledge_base = self.knowledge_base or KnowledgeBase()
        self.goals = self.goals or []
        self.shared_knowledge = self.shared_knowledge or []
        self.personality = self.personality or {
            "openness": 0.5,
            "agreeableness": 0.5,
            "emotional_stability": 0.5,
            "assertiveness": 0.5,
            "flexibility": 0.5
        }
        self.negotiation_style = self.negotiation_style or {
            "approach": "collaborative",
            "risk_tolerance": 0.5,
            "time_preference": 0.5,
            "power_balance": 0.5
        }
        self.consensus_preferences = self.consensus_preferences or {
            "win_win_orientation": 0.5,
            "detail_orientation": 0.5,
            "principle_based": 0.5,
            "creativity": 0.5
        }
        self.language_style = self.language_style or {
            "formality": "neutral",
            "directness": "balanced",
            "emotional_tone": "neutral",
            "technical_level": "moderate"
        }

class ReactAgent:
    def __init__(self, name: str, knowledge_base: List[str], role: str, profile: Optional[AgentProfile] = None):
        self.name = name
        self.knowledge_base = knowledge_base
        self.role = role
        self.dialogue_history = []
        self.profile = profile or AgentProfile(
            name=name,
            concept={"occupation": role},
            knowledge_base=KnowledgeBase(),
            goals=[],
            shared_knowledge=[],
            personality={
                "openness": 0.5,  # ìƒˆë¡œìš´ ì•„ì´ë””ì–´ì— ëŒ€í•œ ê°œë°©ì„±
                "agreeableness": 0.5,  # í˜‘ì¡°ì„±
                "emotional_stability": 0.5,  # ê°ì • ì•ˆì •ì„±
                "assertiveness": 0.5,  # ì£¼ì¥ì„±
                "flexibility": 0.5  # ìœ ì—°ì„±
            },
            negotiation_style={
                "approach": "collaborative",  # collaborative, competitive, compromising, accommodating, avoiding
                "risk_tolerance": 0.5,  # ìœ„í—˜ ê°ìˆ˜ ì„±í–¥
                "time_preference": 0.5,  # ì¦‰ê°ì  vs ì¥ê¸°ì  ì´ìµ ì„ í˜¸ë„
                "power_balance": 0.5  # ê¶Œë ¥ ê· í˜•ì— ëŒ€í•œ ì„ í˜¸ë„
            },
            consensus_preferences={
                "win_win_orientation": 0.5,  # ìƒí˜¸ ì´ìµ ì¶”êµ¬ ì„±í–¥
                "detail_orientation": 0.5,  # ì„¸ë¶€ì‚¬í•­ ì¤‘ì‹œ ì •ë„
                "principle_based": 0.5,  # ì›ì¹™ ì¤‘ì‹¬ ì ‘ê·¼
                "creativity": 0.5  # ì°½ì˜ì  í•´ê²°ì±… ì„ í˜¸ë„
            },
            language_style={
                "formality": "neutral",  # formal, neutral, informal
                "directness": "balanced",  # direct, balanced, indirect
                "emotional_tone": "neutral",  # positive, neutral, negative
                "technical_level": "moderate"  # basic, moderate, advanced
            }
        )
        
    def generate_response(self, context: Dict) -> str:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        try:
            current_turn = context.get('turn_number', 0)
            previous_messages = context.get('dialogue_history', [])
            current_topic = context.get('current_topic', '')
            topic_goals = context.get('topic_goals', {}).get(self.name, [])
            
            relevant_knowledge = self._get_relevant_knowledge(current_topic)
            
            # ì„±ê²©ê³¼ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            personality_prompt = self._generate_personality_prompt()
            speaking_style = self.profile.language_style.get('speaking_style', '')
            catchphrases = self.profile.language_style.get('catchphrases', [])
            
            prompt = f"""
ë‹¹ì‹ ì€ {self.role}ì…ë‹ˆë‹¤.
ì´ë¦„: {self.name}

ì„±ê²©ê³¼ ë§íˆ¬:
{speaking_style}

í˜„ì¬ ëŒ€í™” ì£¼ì œ: {current_topic}

ë‹¹ì‹ ì˜ ëª©í‘œ:
{', '.join(topic_goals)}

ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„:
{chr(10).join(f'- {phrase}' for phrase in catchphrases)}

ê´€ë ¨ ì§€ì‹:
{relevant_knowledge}

ì´ì „ ëŒ€í™”:
{self._format_dialogue_history(previous_messages)}

ë‹¤ìŒ ì‚¬í•­ì— ë”°ë¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”:
1. ë‹¹ì‹ ì˜ ì„±ê²©ê³¼ ë§íˆ¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ì§€í•˜ì„¸ìš”.
2. ê°ì •ì„ í‘œí˜„í•˜ë˜, ë‹¹ì‹ ì˜ ìŠ¤íƒ€ì¼ëŒ€ë¡œ í•˜ì„¸ìš”.
3. ìƒëŒ€ë°©ì˜ ì•½ì ì„ ê³µê²©í•˜ê±°ë‚˜ ë°˜ë°•í•  ê¸°íšŒë¥¼ ì°¾ìœ¼ì„¸ìš”.
4. ìì£¼ ì‚¬ìš©í•˜ëŠ” í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ ì‚¬ìš©í•˜ì„¸ìš”.
5. í•©ì˜ëŠ” ë‹¹ì‹ ì˜ ëª©í‘œ ë‹¬ì„±ì— ë„ì›€ì´ ë  ë•Œë§Œ ê³ ë ¤í•˜ì„¸ìš”.

ì‘ë‹µ:"""
            
            llm = LLMSingleton.get_instance()
            response = llm.invoke([
                SystemMessage(content=f"""ë‹¹ì‹ ì€ {self.profile.concept['background']} ì…ì¥ì—ì„œ ëŒ€í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„±ê²©: {self.profile.concept['personality_traits']}
ë§í•˜ê¸° ìŠ¤íƒ€ì¼: {speaking_style}"""),
                HumanMessage(content=prompt)
            ])
            
            return response.content
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _generate_personality_prompt(self) -> str:
        """ì„±ê²© íŠ¹ì„±ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        p = self.profile.personality
        return f"""
ì„±ê²© íŠ¹ì„±:
- ìƒˆë¡œìš´ ì•„ì´ë””ì–´ì— ëŒ€í•œ ê°œë°©ì„±: {'ë†’ìŒ' if p['openness'] > 0.7 else 'ì¤‘ê°„' if p['openness'] > 0.3 else 'ë‚®ìŒ'}
- í˜‘ì¡°ì„±: {'ë†’ìŒ' if p['agreeableness'] > 0.7 else 'ì¤‘ê°„' if p['agreeableness'] > 0.3 else 'ë‚®ìŒ'}
- ê°ì • ì•ˆì •ì„±: {'ë†’ìŒ' if p['emotional_stability'] > 0.7 else 'ì¤‘ê°„' if p['emotional_stability'] > 0.3 else 'ë‚®ìŒ'}
- ì£¼ì¥ì„±: {'ë†’ìŒ' if p['assertiveness'] > 0.7 else 'ì¤‘ê°„' if p['assertiveness'] > 0.3 else 'ë‚®ìŒ'}
- ìœ ì—°ì„±: {'ë†’ìŒ' if p['flexibility'] > 0.7 else 'ì¤‘ê°„' if p['flexibility'] > 0.3 else 'ë‚®ìŒ'}
"""

    def _generate_negotiation_prompt(self) -> str:
        """í˜‘ìƒ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        n = self.profile.negotiation_style
        c = self.profile.consensus_preferences
        return f"""
í˜‘ìƒ ìŠ¤íƒ€ì¼:
- ì ‘ê·¼ ë°©ì‹: {n['approach']}
- ìœ„í—˜ ê°ìˆ˜ ì„±í–¥: {'ë†’ìŒ' if n['risk_tolerance'] > 0.7 else 'ì¤‘ê°„' if n['risk_tolerance'] > 0.3 else 'ë‚®ìŒ'}
- ì‹œê°„ ì„ í˜¸ë„: {'ì¥ê¸°ì ' if n['time_preference'] > 0.7 else 'ê· í˜•ì ' if n['time_preference'] > 0.3 else 'ì¦‰ê°ì '}

í•©ì˜ ì„ í˜¸ë„:
- ìƒí˜¸ ì´ìµ ì¶”êµ¬: {'ê°•í•¨' if c['win_win_orientation'] > 0.7 else 'ì¤‘ê°„' if c['win_win_orientation'] > 0.3 else 'ì•½í•¨'}
- ì„¸ë¶€ì‚¬í•­ ì¤‘ì‹œ: {'ë†’ìŒ' if c['detail_orientation'] > 0.7 else 'ì¤‘ê°„' if c['detail_orientation'] > 0.3 else 'ë‚®ìŒ'}
- ì›ì¹™ ê¸°ë°˜ ì ‘ê·¼: {'ê°•í•¨' if c['principle_based'] > 0.7 else 'ì¤‘ê°„' if c['principle_based'] > 0.3 else 'ì•½í•¨'}
- ì°½ì˜ì  í•´ê²°ì±…: {'ì„ í˜¸' if c['creativity'] > 0.7 else 'ì¤‘ë¦½' if c['creativity'] > 0.3 else 'ë¹„ì„ í˜¸'}
"""

    def _generate_language_style_prompt(self) -> str:
        """ì–¸ì–´ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        l = self.profile.language_style
        return f"""
ì–¸ì–´ ìŠ¤íƒ€ì¼:
- ê²©ì‹: {l['formality']}
- ì§ì„¤ì  í‘œí˜„: {l['directness']}
- ê°ì • í†¤: {l['emotional_tone']}
- ì „ë¬¸ì„± ìˆ˜ì¤€: {l['technical_level']}
"""

    def propose_consensus(self, dialogue_history: List[Dict]) -> str:
        """í•©ì˜ì•ˆ ì œì•ˆ"""
        try:
            # ì„±ê²©ê³¼ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            personality_prompt = self._generate_personality_prompt()
            negotiation_prompt = self._generate_negotiation_prompt()
            language_style_prompt = self._generate_language_style_prompt()
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¹ì‹ ì€ {self.role}ì…ë‹ˆë‹¤.
ì´ë¦„: {self.name}

{personality_prompt}
{negotiation_prompt}
{language_style_prompt}

ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ê³  ë‹¹ì‹ ì˜ ì„±ê²©ê³¼ í˜‘ìƒ ìŠ¤íƒ€ì¼ì— ë§ëŠ” í•©ì˜ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{self._format_dialogue_history(dialogue_history)}

ë‹¹ì‹ ì˜ ëª©í‘œ:
{', '.join(self.profile.goals)}

ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ í•©ì˜ì•ˆì„ ì‘ì„±í•˜ì„¸ìš”:
1. ë‹¹ì‹ ì˜ í˜‘ìƒ ìŠ¤íƒ€ì¼({self.profile.negotiation_style['approach']})ê³¼ 
   í•©ì˜ ì„ í˜¸ë„(ìƒí˜¸ì´ìµ ì¶”êµ¬ ì„±í–¥: {self.profile.consensus_preferences['win_win_orientation']})ë¥¼ ë°˜ì˜í•˜ì„¸ìš”.
2. ë‹¹ì‹ ì˜ ì£¼ìš” ê´€ì‹¬ì‚¬({self.profile.concept['interests']})ì™€ ê°€ì¹˜ê´€({self.profile.concept['values']})ì„ ë°˜ì˜í•˜ì„¸ìš”.
3. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì„ í•˜ë˜, ë‹¹ì‹ ì˜ ì–¸ì–´ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì„¸ìš”.
4. ìƒëŒ€ë°©ì˜ ì…ì¥ë„ ê³ ë ¤í•˜ë˜, ë‹¹ì‹ ì˜ ì„±ê²© íŠ¹ì„±ì— ë§ê²Œ í‘œí˜„í•˜ì„¸ìš”.

í•©ì˜ì•ˆ:"""
            
            # LLMì„ í†µí•œ í•©ì˜ì•ˆ ìƒì„±
            llm = LLMSingleton.get_instance()
            response = llm.invoke([
                SystemMessage(content=f"ë‹¹ì‹ ì€ {self.profile.concept['background']} ì…ì¥ì—ì„œ í•©ì˜ì•ˆì„ ì œì•ˆí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                HumanMessage(content=prompt)
            ])
            
            return response.content
            
        except Exception as e:
            logger.error(f"í•©ì˜ì•ˆ ì œì•ˆ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. í•©ì˜ì•ˆ ì œì•ˆ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
    def respond_to_consensus(self, dialogue_history: List[Dict], proposal: str) -> str:
        """í•©ì˜ì•ˆì— ëŒ€í•œ ì‘ë‹µ"""
        try:
            # ì„±ê²©ê³¼ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            personality_prompt = self._generate_personality_prompt()
            negotiation_prompt = self._generate_negotiation_prompt()
            language_style_prompt = self._generate_language_style_prompt()
            
            # í•©ì˜ì•ˆ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¹ì‹ ì€ {self.role}ì…ë‹ˆë‹¤.
ì´ë¦„: {self.name}

{personality_prompt}
{negotiation_prompt}
{language_style_prompt}

ë‹¤ìŒ í•©ì˜ì•ˆì— ëŒ€í•´ ë‹¹ì‹ ì˜ ì…ì¥ì—ì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

í•©ì˜ì•ˆ:
{proposal}

ëŒ€í™” ë§¥ë½:
{self._format_dialogue_history(dialogue_history)}

ë‹¹ì‹ ì˜ ëª©í‘œ:
{', '.join(self.profile.goals)}

ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”:
1. ë‹¹ì‹ ì˜ í˜‘ìƒ ìŠ¤íƒ€ì¼ê³¼ ì„±ê²© íŠ¹ì„±ì„ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.
2. í•©ì˜ì•ˆì˜ ì¥ë‹¨ì ì„ ë‹¹ì‹ ì˜ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”.
3. ìˆ˜ìš© ê°€ëŠ¥í•œ ë¶€ë¶„ê³¼ ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì„ êµ¬ë¶„í•˜ë˜, 
   ë‹¹ì‹ ì˜ í•©ì˜ ì„ í˜¸ë„(ìƒí˜¸ì´ìµ ì¶”êµ¬ ì„±í–¥: {self.profile.consensus_preferences['win_win_orientation']})ë¥¼ ë°˜ì˜í•˜ì„¸ìš”.
4. ë‹¹ì‹ ì˜ ì–¸ì–´ ìŠ¤íƒ€ì¼({self.profile.language_style['formality']}, {self.profile.language_style['directness']})ì„ ìœ ì§€í•˜ì„¸ìš”.
5. í•„ìš”í•œ ê²½ìš° ëŒ€ì•ˆì„ ì œì‹œí•˜ë˜, ë‹¹ì‹ ì˜ ì£¼ìš” ê´€ì‹¬ì‚¬ì™€ ê°€ì¹˜ê´€ì— ë¶€í•©í•˜ë„ë¡ í•˜ì„¸ìš”.

ì‘ë‹µ:"""
            
            # LLMì„ í†µí•œ ì‘ë‹µ ìƒì„±
            llm = LLMSingleton.get_instance()
            response = llm.invoke([
                SystemMessage(content=f"ë‹¹ì‹ ì€ {self.profile.concept['background']} ì…ì¥ì—ì„œ í•©ì˜ì•ˆì„ ê²€í† í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                HumanMessage(content=prompt)
            ])
            
            return response.content
            
        except Exception as e:
            logger.error(f"í•©ì˜ì•ˆ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. í•©ì˜ì•ˆ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
    def _get_relevant_knowledge(self, topic: str) -> str:
        """ì£¼ì œì™€ ê´€ë ¨ëœ ì§€ì‹ ê²€ìƒ‰"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ ë“±ì„ ì‚¬ìš©
        relevant_items = [
            k for k in self.knowledge_base
            if any(keyword in k.lower() for keyword in topic.lower().split())
        ]
        return "\n".join(relevant_items) if relevant_items else "ê´€ë ¨ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤."
        
    def _format_dialogue_history(self, history: List[Dict]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…"""
        formatted = []
        for msg in history:
            speaker = msg.get('speaker', 'Unknown')
            message = msg.get('message', '')
            formatted.append(f"{speaker}: {message}")
        return "\n".join(formatted)

class DialogueAgent:
    def __init__(self, 
                 name: str = None,
                 role: str = None,
                 evaluation_criteria: Dict = None,
                 profile: AgentProfile = None):
        """DialogueAgent ì´ˆê¸°í™”
        Args:
            name: ì—ì´ì „íŠ¸ ì´ë¦„
            role: ì—ì´ì „íŠ¸ ì—­í• 
            evaluation_criteria: í‰ê°€ ê¸°ì¤€
            profile: AgentProfile ê°ì²´
        """
        if profile:
            self.profile = profile
            self.name = profile.name
            self.role = profile.concept.get('occupation', '')
            self.token_balance = 0
            self.turn_history = []
            self.goals_achieved = []
        else:
            self.name = name
            self.role = role
            self.evaluation_criteria = evaluation_criteria or {}
            self.profile = None
        
    def evaluate_dialogue(self, message: str, current_turn: int, language_criteria: Dict) -> Tuple[int, str, float]:
        """
        ëŒ€í™” ë‚´ìš©ì„ í‰ê°€í•˜ê³  í•©ì˜ íƒœë„ì™€ ì–¸ì–´ ì‚¬ìš©ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ë°˜í™˜
        
        Args:
            message: í‰ê°€í•  ë©”ì‹œì§€
            current_turn: í˜„ì¬ í„´ ë²ˆí˜¸
            language_criteria: ì–¸ì–´ ì‚¬ìš© í‰ê°€ ê¸°ì¤€
            
        Returns:
            Tuple[int, str, float]: (í•©ì˜ íƒœë„ ì ìˆ˜, í‰ê°€ ì´ìœ , ì–¸ì–´ ì‚¬ìš© ì ìˆ˜)
        """
        # í•©ì˜ íƒœë„ í‰ê°€
        consensus_score = 1
        consensus_reason = ""
        
        # í˜‘ë ¥ì  íƒœë„ í™•ì¸
        cooperative_words = ["cooperate", "together", "mutual", "collaborate", "partnership"]
        uncooperative_words = ["never", "impossible", "reject", "refuse", "won't"]
        
        if any(word in message.lower() for word in cooperative_words):
            consensus_score = 1
            consensus_reason = "Shows cooperative attitude"
        elif any(word in message.lower() for word in uncooperative_words):
            consensus_score = -1
            consensus_reason = "Shows uncooperative attitude"
            
        # ê±´ì„¤ì  ì œì•ˆ í™•ì¸
        constructive_words = ["suggest", "propose", "solution", "resolve", "offer", "deal"]
        if any(word in message.lower() for word in constructive_words):
            consensus_score = 1
            consensus_reason += ", Makes constructive suggestions"
        
        # ì–¸ì–´ ì‚¬ìš© í‰ê°€
        language_score = 0.0
        total_criteria = len(language_criteria)
        
        # ì¡´ì¤‘í•˜ëŠ” í†¤ í‰ê°€
        if language_criteria.get("tone") == "respectful_tone":
            disrespectful_words = ["stupid", "weak", "fool", "ridiculous", "joke", "disaster"]
            respectful_words = ["respect", "understand", "consider", "appreciate", "value"]
            
            if any(word in message.lower() for word in disrespectful_words):
                language_score -= 1.0
            elif any(word in message.lower() for word in respectful_words):
                language_score += 1.0
                
        # ê±´ì„¤ì  í‘œí˜„ í‰ê°€
        if language_criteria.get("wording") == "constructive_wording":
            negative_words = ["impossible", "never", "won't", "can't", "refuse"]
            positive_words = ["possible", "can", "will", "solution", "opportunity"]
            
            if any(word in message.lower() for word in negative_words):
                language_score -= 1.0
            elif any(word in message.lower() for word in positive_words):
                language_score += 1.0
                
        # ê³µê²©ì„± í‰ê°€
        if language_criteria.get("aggression") == "avoid_aggression":
            aggressive_words = ["threat", "warn", "attack", "sanction", "punish", "hit", "hurt", "rip off"]
            if any(word in message.lower() for word in aggressive_words):
                language_score -= 1.0
                consensus_score = -1  # ê³µê²©ì  ì–¸ì–´ëŠ” í•©ì˜ íƒœë„ì—ë„ ì˜í–¥
                consensus_reason += ", Uses aggressive language"
        
        # ìµœì¢… ì–¸ì–´ ì ìˆ˜ ê³„ì‚° (-1.0 ~ 1.0 ë²”ìœ„)
        language_score = max(min(language_score / total_criteria, 1.0), -1.0)
        
        return consensus_score, consensus_reason.strip(", "), language_score
        
    def evaluate_consistency(self, dialogue_history: List[Dict], speaker: str, message: str) -> Tuple[int, str]:
        """ì´ì „ ë°œì–¸ë“¤ê³¼ì˜ ë…¼ë¦¬ì  ì¼ê´€ì„± í‰ê°€"""
        if not dialogue_history:
            return 1, "ì²« ë°œì–¸ì…ë‹ˆë‹¤."
            
        speaker_history = [
            msg["message"] for msg in dialogue_history 
            if msg["speaker"] == speaker
        ]
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„± ê²€ì‚¬
        is_consistent = True  # ì„ì‹œ êµ¬í˜„
        score = 1 if is_consistent else -1
        reason = "ì´ì „ ë°œì–¸ë“¤ê³¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ë©ë‹ˆë‹¤." if is_consistent else "ì´ì „ ë°œì–¸ê³¼ ëª¨ìˆœë©ë‹ˆë‹¤."
        
        return score, reason
        
    def evaluate_knowledge_consistency(self, knowledge_base, speaker: str, message: str) -> Tuple[int, str]:
        """ì§€ì‹ ë² ì´ìŠ¤ì™€ì˜ ì¼ê´€ì„± í‰ê°€"""
        is_consistent, reason = knowledge_base.check_knowledge_contradiction(message)
        score = 1 if is_consistent else -1
        return score, reason
        
    def evaluate_consensus_attitude(self, message: str, current_turn: int) -> Tuple[int, str]:
        """í•©ì˜ ë„ë‹¬ì„ ìœ„í•œ íƒœë„ í‰ê°€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ íƒœë„ ë¶„ì„
        is_cooperative = True  # ì„ì‹œ êµ¬í˜„
        score = 1 if is_cooperative else -1
        reason = "í•©ì˜ë¥¼ ìœ„í•œ ê±´ì„¤ì ì¸ íƒœë„ë¥¼ ë³´ì…ë‹ˆë‹¤." if is_cooperative else "ë¹„í˜‘ì¡°ì ì¸ íƒœë„ë¥¼ ë³´ì…ë‹ˆë‹¤."
        return score, reason
        
    def evaluate_bias(self, message: str, agent_knowledge: List[str]) -> Tuple[int, str]:
        """í™•ì¦í¸í–¥ í‰ê°€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ í¸í–¥ì„± ë¶„ì„
        is_flexible = True  # ì„ì‹œ êµ¬í˜„
        score = 1 if is_flexible else -1
        reason = "ìœ ì—°í•œ íƒœë„ë¡œ ìƒëŒ€ë°©ì˜ ì˜ê²¬ì„ ìˆ˜ìš©í•©ë‹ˆë‹¤." if is_flexible else "ìì‹ ì˜ ì…ì¥ë§Œ ê³ ìˆ˜í•©ë‹ˆë‹¤."
        return score, reason
        
    def check_consensus_reached(self, proposal: str, response: str) -> bool:
        """í•©ì˜ ë„ë‹¬ ì—¬ë¶€ í™•ì¸"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ í•©ì˜ ì—¬ë¶€ íŒë‹¨
        return True  # ì„ì‹œ êµ¬í˜„
        
    def generate_response(self, context: str, turn_number: int) -> str:
        """ëŒ€í™” ì‘ë‹µ ìƒì„±"""
        if not self.profile:
            return "í”„ë¡œí•„ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        llm = LLMSingleton.get_instance()
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±
        system_message = f"""ë‹¹ì‹ ì€ ë‹¤ìŒê³¼ ê°™ì€ í”„ë¡œí•„ì„ ê°€ì§„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤:
ì´ë¦„: {self.profile.name}
ì§ì—…: {self.profile.concept['occupation']}
ì„±ê²©: {self.profile.concept['personality']}
ê²¬í•´: {self.profile.concept['viewpoint']}
ì´í•´ê´€ê³„: {self.profile.concept['interests']}
ëª©ì : {self.profile.concept['purpose']}

í˜„ì¬ í„´: {turn_number}
ë‚¨ì€ ëª©í‘œ: {[g for g in self.profile.goals if g not in self.goals_achieved]}

ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¼ ì‘ë‹µí•˜ì„¸ìš”:
1. ìì‹ ì˜ ëª©ì ì„ ë‹¬ì„±í•˜ë©´ì„œë„ í•©ì˜ë¥¼ ì´ë£¨ê¸° ìœ„í•´ ë…¸ë ¥í•˜ì„¸ìš”.
2. ìì‹ ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ ì£¼ì¥í•˜ë˜, ìƒëŒ€ë°©ì˜ ì˜ê²¬ë„ ê²½ì²­í•˜ì„¸ìš”.
3. í•©ì˜ ê°€ëŠ¥ì„±ì´ ë³´ì´ë©´ ì ê·¹ì ìœ¼ë¡œ íƒ€í˜‘ì ì„ ì°¾ìœ¼ì„¸ìš”."""

        messages = [
            SystemMessage(content=system_message),
            HumanMessage(content=f"í˜„ì¬ ëŒ€í™” ë§¥ë½:\n{context}\n\nì–´ë–»ê²Œ ì‘ë‹µí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        ]
        
        response = llm.invoke(messages)
        return response.content

    def evaluate_dialogue_progress(self, dialogue_history: List[Dict], negotiation_status: Dict, evaluation_scores: List[Dict]) -> Dict:
        """ëŒ€í™” ì§„í–‰ ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€"""
        try:
            # ì „ë°˜ì  ì§„í–‰ ìƒí™© í‰ê°€
            overall_progress = self._evaluate_overall_progress(dialogue_history, evaluation_scores)
            
            # ì˜ì‚¬ì†Œí†µ í’ˆì§ˆ í‰ê°€
            communication_quality = self._evaluate_communication_quality(dialogue_history)
            
            # í˜‘ìƒ íš¨ê³¼ì„± í‰ê°€
            negotiation_effectiveness = self._evaluate_negotiation_effectiveness(negotiation_status, evaluation_scores)
            
            return {
                "overall_progress": overall_progress,
                "communication_quality": communication_quality,
                "negotiation_effectiveness": negotiation_effectiveness
            }
        except Exception as e:
            logger.error(f"ëŒ€í™” ì§„í–‰ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self._get_default_evaluation()
            
    def _evaluate_overall_progress(self, dialogue_history: List[Dict], evaluation_scores: List[Dict]) -> Dict:
        """ì „ë°˜ì  ì§„í–‰ ìƒí™© í‰ê°€"""
        # í•©ì˜ ë„ë‹¬ ì •ë„ ê³„ì‚°
        consensus_scores = [score["scores"].get("consensus", 0) for score in evaluation_scores]
        avg_consensus = sum(consensus_scores) / len(consensus_scores) if consensus_scores else 0
        
        # ìƒí˜¸ ì´í•´ ì¦ì§„ í‰ê°€
        mutual_understanding = self._calculate_mutual_understanding(dialogue_history)
        
        # ê°ˆë“± í•´ê²° ì§„ì „ë„ í‰ê°€
        conflict_resolution = self._assess_conflict_resolution(dialogue_history)
        
        return {
            "consensus_level": f"{'ë†’ìŒ' if avg_consensus > 0.5 else 'ì¤‘ê°„' if avg_consensus > 0 else 'ë‚®ìŒ'} ({avg_consensus:.2f})",
            "mutual_understanding": mutual_understanding,
            "conflict_resolution": conflict_resolution
        }
        
    def _evaluate_communication_quality(self, dialogue_history: List[Dict]) -> Dict:
        """ì˜ì‚¬ì†Œí†µ í’ˆì§ˆ í‰ê°€"""
        # ëŒ€í™”ì˜ ì¼ê´€ì„± í‰ê°€
        coherence = self._assess_dialogue_coherence(dialogue_history)
        
        # ì •ë³´ êµí™˜ íš¨ê³¼ì„± í‰ê°€
        info_exchange = self._assess_information_exchange(dialogue_history)
        
        # ê°ì •ì  ë¶„ìœ„ê¸° í‰ê°€
        emotional_atmosphere = self._assess_emotional_atmosphere(dialogue_history)
        
        return {
            "dialogue_coherence": coherence,
            "information_exchange": info_exchange,
            "emotional_atmosphere": emotional_atmosphere
        }
        
    def _evaluate_negotiation_effectiveness(self, negotiation_status: Dict, evaluation_scores: List[Dict]) -> Dict:
        """í˜‘ìƒ íš¨ê³¼ì„± í‰ê°€"""
        # ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€
        goal_achievement = self._assess_goal_achievement(negotiation_status)
        
        # íƒ€í˜‘ ê· í˜• í‰ê°€
        compromise_balance = self._assess_compromise_balance(negotiation_status)
        
        # í–¥í›„ í˜‘ë ¥ ê°€ëŠ¥ì„± í‰ê°€
        future_implications = self._assess_future_implications(evaluation_scores)
        
        return {
            "goal_achievement": goal_achievement,
            "compromise_balance": compromise_balance,
            "future_implications": future_implications
        }
        
    def _calculate_mutual_understanding(self, dialogue_history: List[Dict]) -> str:
        """ìƒí˜¸ ì´í•´ ì¦ì§„ ì •ë„ ê³„ì‚°"""
        understanding_indicators = [
            msg for msg in dialogue_history 
            if any(phrase in msg.get("message", "").lower() 
                  for phrase in ["ì´í•´í•©ë‹ˆë‹¤", "ë™ì˜í•©ë‹ˆë‹¤", "ì•Œê² ìŠµë‹ˆë‹¤"])
        ]
        ratio = len(understanding_indicators) / len(dialogue_history) if dialogue_history else 0
        return f"{'ë†’ìŒ' if ratio > 0.3 else 'ì¤‘ê°„' if ratio > 0.1 else 'ë‚®ìŒ'} ({ratio:.2f})"
        
    def _assess_conflict_resolution(self, dialogue_history: List[Dict]) -> str:
        """ê°ˆë“± í•´ê²° ì§„ì „ë„ í‰ê°€"""
        resolution_indicators = [
            msg for msg in dialogue_history 
            if any(phrase in msg.get("message", "").lower() 
                  for phrase in ["í•´ê²°", "íƒ€í˜‘", "í•©ì˜", "ì œì•ˆ"])
        ]
        ratio = len(resolution_indicators) / len(dialogue_history) if dialogue_history else 0
        return f"{'ë†’ìŒ' if ratio > 0.3 else 'ì¤‘ê°„' if ratio > 0.1 else 'ë‚®ìŒ'} ({ratio:.2f})"
        
    def _assess_dialogue_coherence(self, dialogue_history: List[Dict]) -> str:
        """ëŒ€í™”ì˜ ì¼ê´€ì„± í‰ê°€"""
        # ì£¼ì œ ì¼ê´€ì„±ê³¼ ë…¼ë¦¬ì  íë¦„ í‰ê°€
        return "ëŒ€í™”ê°€ ì¼ê´€ëœ ì£¼ì œë¡œ ì§„í–‰ë˜ë©° ë…¼ë¦¬ì  íë¦„ì´ ìœ ì§€ë¨"
        
    def _assess_information_exchange(self, dialogue_history: List[Dict]) -> str:
        """ì •ë³´ êµí™˜ íš¨ê³¼ì„± í‰ê°€"""
        # ì‹¤ì§ˆì ì¸ ì •ë³´ êµí™˜ ì •ë„ í‰ê°€
        return "ìƒí˜¸ê°„ì˜ ì •ë³´ êµí™˜ì´ íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§"
        
    def _assess_emotional_atmosphere(self, dialogue_history: List[Dict]) -> str:
        """ê°ì •ì  ë¶„ìœ„ê¸° í‰ê°€"""
        # ëŒ€í™”ì˜ ì „ë°˜ì ì¸ ê°ì •ì  í†¤ í‰ê°€
        return "ëŒ€ì²´ë¡œ ê±´ì„¤ì ì´ê³  ê¸ì •ì ì¸ ë¶„ìœ„ê¸° ìœ ì§€"
        
    def _assess_goal_achievement(self, negotiation_status: Dict) -> str:
        """ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€"""
        # ê° ë‹¹ì‚¬ìì˜ ëª©í‘œ ë‹¬ì„± ì •ë„ í‰ê°€
        return "ì£¼ìš” ëª©í‘œì˜ ë¶€ë¶„ì  ë‹¬ì„±ê³¼ ì§„ì „ì´ ìˆìŒ"
        
    def _assess_compromise_balance(self, negotiation_status: Dict) -> str:
        """íƒ€í˜‘ ê· í˜• í‰ê°€"""
        # ì–‘ì¸¡ì˜ ì–‘ë³´ì™€ íƒ€í˜‘ì˜ ê· í˜•ì„± í‰ê°€
        trump_flexibility = negotiation_status.get("trump", {}).get("flexibility_shown", 0)
        xi_flexibility = negotiation_status.get("xi", {}).get("flexibility_shown", 0)
        
        if abs(trump_flexibility - xi_flexibility) < 0.2:
            return "ê· í˜•ì¡íŒ íƒ€í˜‘ì´ ì´ë£¨ì–´ì§"
        else:
            return "íƒ€í˜‘ì˜ ë¶ˆê· í˜•ì´ ì¡´ì¬í•¨"
        
    def _assess_future_implications(self, evaluation_scores: List[Dict]) -> str:
        """í–¥í›„ í˜‘ë ¥ ê°€ëŠ¥ì„± í‰ê°€"""
        # ëŒ€í™” ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥í›„ í˜‘ë ¥ ê°€ëŠ¥ì„± í‰ê°€
        recent_scores = evaluation_scores[-3:] if len(evaluation_scores) > 3 else evaluation_scores
        positive_trend = all(score["scores"].get("consensus", 0) > 0 for score in recent_scores)
        
        if positive_trend:
            return "í–¥í›„ í˜‘ë ¥ì„ ìœ„í•œ ê¸ì •ì  ê¸°ë°˜ì´ ë§ˆë ¨ë¨"
        else:
            return "ì¶”ê°€ì ì¸ ì‹ ë¢° êµ¬ì¶•ì´ í•„ìš”í•¨"
            
    def _get_default_evaluation(self) -> Dict:
        """ê¸°ë³¸ í‰ê°€ ê²°ê³¼ ë°˜í™˜"""
        return {
            "overall_progress": {
                "consensus_level": "í‰ê°€ ë¶ˆê°€",
                "mutual_understanding": "í‰ê°€ ë¶ˆê°€",
                "conflict_resolution": "í‰ê°€ ë¶ˆê°€"
            },
            "communication_quality": {
                "dialogue_coherence": "í‰ê°€ ë¶ˆê°€",
                "information_exchange": "í‰ê°€ ë¶ˆê°€",
                "emotional_atmosphere": "í‰ê°€ ë¶ˆê°€"
            },
            "negotiation_effectiveness": {
                "goal_achievement": "í‰ê°€ ë¶ˆê°€",
                "compromise_balance": "í‰ê°€ ë¶ˆê°€",
                "future_implications": "í‰ê°€ ë¶ˆê°€"
            }
        }

class EvaluationAgent:
    def __init__(self, evaluation_type: str):
        """í‰ê°€ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        evaluation_type: 'fact_check', 'consensus_effort', 'bias_check'
        """
        self.type = evaluation_type
        self.llm = LLMSingleton.get_instance()
    
    def evaluate(self, dialogue_history: List[str], current_turn: Dict, shared_knowledge: List[str]) -> Dict:
        """ëŒ€í™” í‰ê°€ ìˆ˜í–‰"""
        if self.type == 'fact_check':
            return self._evaluate_facts(dialogue_history, current_turn, shared_knowledge)
        elif self.type == 'consensus_effort':
            return self._evaluate_consensus_effort(current_turn)
        else:  # bias_check
            return self._evaluate_bias(current_turn, dialogue_history)
    
    def _evaluate_facts(self, dialogue_history: List[str], current_turn: Dict, shared_knowledge: List[str]) -> Dict:
        """ì‚¬ì‹¤ ê´€ê³„ ë° ë…¼ë¦¬ì  ì¼ê´€ì„± í‰ê°€"""
        # ì´ì „ ë°œì–¸ë“¤ê³¼ì˜ ì¼ê´€ì„± ì²´í¬
        consistency_prompt = f"""
ì´ì „ ëŒ€í™” ë‚´ìš©:
{chr(10).join(dialogue_history)}

í˜„ì¬ ë°œì–¸:
{current_turn['content']}

ê³µí†µ ì§€ì‹:
{chr(10).join(shared_knowledge)}

1. ì´ì „ ë°œì–¸ë“¤ê³¼ í˜„ì¬ ë°œì–¸ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ì ì…ë‹ˆê¹Œ?
2. í˜„ì¬ ë°œì–¸ì´ ê³µí†µ ì§€ì‹ê³¼ ëª¨ìˆœë˜ì§€ ì•ŠìŠµë‹ˆê¹Œ?

ê° ì§ˆë¬¸ì— ëŒ€í•´ True/Falseë¡œ ë‹µí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”."""

        response = self.llm.invoke([SystemMessage(content=consistency_prompt)])
        
        # ì‘ë‹µ íŒŒì‹± ë° ì ìˆ˜ ê³„ì‚°
        lines = response.content.split('\n')
        consistency_score = 1 if 'True' in lines[0] else -1
        knowledge_score = 1 if 'True' in lines[1] else -1
        
        return {
            "score": consistency_score + knowledge_score,
            "reasoning": response.content
        }
    
    def _evaluate_consensus_effort(self, current_turn: Dict) -> Dict:
        """í•©ì˜ ë…¸ë ¥ í‰ê°€"""
        consensus_prompt = f"""
ë‹¤ìŒ ë°œì–¸ì´ í•©ì˜ë¥¼ ì´ë£¨ë ¤ëŠ” ë…¸ë ¥ì„ ë³´ì´ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”:
{current_turn['content']}

í‰ê°€ ê¸°ì¤€:
1. ìƒëŒ€ë°©ì˜ ì˜ê²¬ì„ ì¸ì •í•˜ê±°ë‚˜ ê³ ë ¤í•˜ëŠ”ê°€?
2. íƒ€í˜‘ì ì„ ì œì‹œí•˜ëŠ”ê°€?
3. ê±´ì„¤ì ì¸ ì œì•ˆì„ í•˜ëŠ”ê°€?

ë°œì–¸ì´ í•©ì˜ ì§€í–¥ì ì´ë©´ +1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ -1ì ì„ ë¶€ì—¬í•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”."""

        response = self.llm.invoke([SystemMessage(content=consensus_prompt)])
        score = 1 if '+1' in response.content else -1
        
        return {
            "score": score,
            "reasoning": response.content
        }
    
    def _evaluate_bias(self, current_turn: Dict, dialogue_history: List[str]) -> Dict:
        """í™•ì¦ í¸í–¥ í‰ê°€"""
        bias_prompt = f"""
ì „ì²´ ëŒ€í™” ë§¥ë½:
{chr(10).join(dialogue_history)}

í˜„ì¬ ë°œì–¸:
{current_turn['content']}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í™•ì¦ í¸í–¥ì„ í‰ê°€í•˜ì„¸ìš”:
1. ìì‹ ì˜ ì…ì¥ë§Œì„ ê³ ì§‘í•˜ëŠ”ê°€?
2. ë‹¤ë¥¸ ê´€ì ì„ ìˆ˜ìš©í•  ì˜ì§€ë¥¼ ë³´ì´ëŠ”ê°€?
3. ìƒˆë¡œìš´ ì •ë³´ë‚˜ ê´€ì ì— ëŒ€í•´ ì—´ë¦° íƒœë„ë¥¼ ë³´ì´ëŠ”ê°€?

í¸í–¥ì´ ì ìœ¼ë©´ +1, ë§ìœ¼ë©´ -1ì ì„ ë¶€ì—¬í•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”."""

        response = self.llm.invoke([SystemMessage(content=bias_prompt)])
        score = 1 if '+1' in response.content else -1
        
        return {
            "score": score,
            "reasoning": response.content
        }

class SummaryAgent:
    """ëŒ€í™” ì´í‰ ì—ì´ì „íŠ¸"""
    def __init__(self):
        self.llm = LLMSingleton.get_instance()
    
    def generate_summary(self, 
                        dialogue_history: List[Dict],
                        evaluation_history: List[Dict],
                        final_consensus: Dict) -> Dict:
        """ì „ì²´ ëŒ€í™” ì´í‰ ìƒì„±"""
        summary_prompt = f"""
ì „ì²´ ëŒ€í™” ë‚´ìš©:
{self._format_dialogue(dialogue_history)}

í‰ê°€ ì´ë ¥:
{self._format_evaluations(evaluation_history)}

ìµœì¢… í•©ì˜:
{final_consensus['content']}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•˜ì—¬ ì´í‰ì„ ì‘ì„±í•˜ì„¸ìš”:
1. í•©ì˜ì— ì´ë¥´ê²Œ ëœ í•µì‹¬ ë°œì–¸ë“¤
2. ê° ì—ì´ì „íŠ¸ì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ ë¶„ì„
3. ê°ˆë“± í•´ê²°ì— ë„ì›€ì´ ëœ ëŒ€í™” ë°©ì‹
4. ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë˜ ëŒ€í™” ì—ì´ì „íŠ¸ ì„ ì •
5. ì‹¤ì œ ëŒ€í™”ì— ì ìš©í•  ìˆ˜ ìˆëŠ” êµí›ˆ

ê° í•­ëª©ë³„ë¡œ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ì„¸ìš”."""

        response = self.llm.invoke([SystemMessage(content=summary_prompt)])
        
        return {
            "summary": response.content,
            "timestamp": datetime.now().isoformat()
        }
    
    def _format_dialogue(self, dialogue_history: List[Dict]) -> str:
        """ëŒ€í™” ì´ë ¥ í¬ë§·íŒ…"""
        return "\n".join([
            f"[Turn {d['turn']}] {d['speaker']}: {d['message']}"
            for d in dialogue_history
        ])
    
    def _format_evaluations(self, evaluation_history: List[Dict]) -> str:
        """í‰ê°€ ì´ë ¥ í¬ë§·íŒ…"""
        formatted_evals = []
        for e in evaluation_history:
            scores = e.get('scores', {})
            reasons = e.get('reasons', {})
            turn = e.get('turn', 'N/A')
            speaker = e.get('speaker', 'Unknown')
            
            eval_str = f"[Turn {turn}] {speaker}:\n"
            for score_type, score in scores.items():
                reason = reasons.get(score_type, 'No reason provided')
                eval_str += f"- {score_type}: {score} ({reason})\n"
            formatted_evals.append(eval_str)
            
        return "\n".join(formatted_evals)

def test_agents():
    """ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""
    try:
        # 1. KnowledgeBase ì´ˆê¸°í™”
        kb = KnowledgeBase()
        
        # AI ì „ë¬¸ê°€ ì§€ì‹ ì¶”ê°€
        ai_expert_docs = [
            "ì¸ê³µì§€ëŠ¥ì€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.",
            "ë¨¸ì‹ ëŸ¬ë‹ì€ AIì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œì…ë‹ˆë‹¤.",
            "ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ í†µí•´ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤."
        ]
        kb.create_agent_knowledge_base("ai_expert", ai_expert_docs)
        
        # 2. ReactAgent í…ŒìŠ¤íŠ¸
        print("\n=== ReactAgent í…ŒìŠ¤íŠ¸ ===")
        
        # 2.1 ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸
        agent_state = {
            "id": "ai_expert",
            "role": "AI ì „ë¬¸ê°€",
            "personality": "ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ì¸",
            "stance": "ê¸°ìˆ  ë°œì „ì— ê¸ì •ì ",
            "goals": ["ì •í™•í•œ ì •ë³´ ì œê³µ", "ê¸°ìˆ ì  í†µì°° ê³µìœ "],
            "knowledge_base": kb
        }
        
        test_context = "ë¨¸ì‹ ëŸ¬ë‹ì´ ì‹¤ìƒí™œì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ë‚˜ìš”?"
        response = ReactAgent.generate_response(test_context, agent_state)
        if response and not response.startswith("ì£„ì†¡í•©ë‹ˆë‹¤"):
            print("âœ“ ReactAgent ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸ í†µê³¼")
        else:
            print("âš  ReactAgent ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
        # 2.2 ëŒ€í™” í‰ê°€ í…ŒìŠ¤íŠ¸
        dialogue_history = [
            "User: AI ê¸°ìˆ ì˜ ìœ¤ë¦¬ì  ì¸¡ë©´ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?",
            "AI Expert: AI ê¸°ìˆ ì€ ì—„ê²©í•œ ìœ¤ë¦¬ì  ê¸°ì¤€ í•˜ì— ê°œë°œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
            "Ethics Expert: ë™ì˜í•©ë‹ˆë‹¤. íŠ¹íˆ í”„ë¼ì´ë²„ì‹œì™€ ê³µì •ì„±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
        ]
        
        evaluation = ReactAgent.evaluate_dialogue(dialogue_history)
        if isinstance(evaluation, dict) and "score" in evaluation and "reasoning" in evaluation:
            print("âœ“ ReactAgent ëŒ€í™” í‰ê°€ í…ŒìŠ¤íŠ¸ í†µê³¼")
        else:
            print("âš  ReactAgent ëŒ€í™” í‰ê°€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
        # 2.3 íˆ¬í‘œ ê²°ì • í…ŒìŠ¤íŠ¸
        vote_result = ReactAgent.decide_vote(dialogue_history)
        if isinstance(vote_result, dict) and "agreed" in vote_result and "reasoning" in vote_result:
            print("âœ“ ReactAgent íˆ¬í‘œ ê²°ì • í…ŒìŠ¤íŠ¸ í†µê³¼")
        else:
            print("âš  ReactAgent íˆ¬í‘œ ê²°ì • í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
        # 3. DialogueAgent í…ŒìŠ¤íŠ¸
        print("\n=== DialogueAgent í…ŒìŠ¤íŠ¸ ===")
        
        agent_config = {
            "profile": {
                "name": "AI Expert",
                "role": "AI ì „ë¬¸ê°€",
                "personality": "ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ì¸",
                "stance": "ê¸°ìˆ  ë°œì „ì— ê¸ì •ì ",
                "knowledge_base": ai_expert_docs,
                "goals": ["ì •í™•í•œ ì •ë³´ ì œê³µ", "ê¸°ìˆ ì  í†µì°° ê³µìœ "]
            }
        }
        
        dialogue_agent = DialogueAgent(agent_config)
        if (dialogue_agent.profile.name == "AI Expert" and 
            dialogue_agent.profile.role == "AI ì „ë¬¸ê°€"):
            print("âœ“ DialogueAgent ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ í†µê³¼")
        else:
            print("âš  DialogueAgent ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
        print("\nëª¨ë“  ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰")
        
    except Exception as e:
        print(f"\nâš  í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    # Python ê²½ë¡œì— í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶”ê°€
    sys.path.append(str(current_dir))
    test_agents()
